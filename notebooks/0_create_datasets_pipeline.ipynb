{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity Profile\n",
    "\n",
    "Goal: decomposition of diversity dimensions to allow a comprehensive evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.coverage as cov\n",
    "import src.frequency_profiling as occ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 Create multiple toy datasets for different diversity scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These toy datasets can be used for test scenarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Manual toy datasets for controlled outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case: dataframe with all static columns each with 1 value\n",
    "df_static = pd.DataFrame({'model': ['_a']*1000,\n",
    "                     'manufacturer': ['_b']*1000,\n",
    "                        'version': ['_c']*1000,\n",
    "                            'country': ['_d']*1000,\n",
    "                                'region': ['_e']*1000,\n",
    "                                    'wholesaler': ['_f']*1000,})\n",
    "\n",
    "df_static.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_static.to_csv('data/df_static.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one combination / one pattern in the data. But this pattern is covered. And all of its children patterns are also covered. We have no uncovered patterns (or mups). Hence coverage is 100%.\n",
    "\n",
    "\n",
    "However, the diversity must still be low because it is only one pattern in the data. -> low variance, high coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case: 10 categorical columns with random data\n",
    "\n",
    "# Define the categories for each attribute\n",
    "categories = {\n",
    "    'Attribute1': ['A', 'B', 'C', 'D'],\n",
    "    'Attribute2': ['X', 'Y', 'Z'],\n",
    "    'Attribute3': ['M', 'N', 'O', 'P', 'Q'],\n",
    "    'Attribute4': ['Alpha', 'Beta'],\n",
    "    'Attribute5': ['Red', 'Green', 'Blue', 'Yellow'],\n",
    "    'Attribute6': ['One', 'Two', 'Three', 'Four', 'Five', 'Six'],\n",
    "    'Attribute7': ['Apple', 'Banana', 'Orange'],\n",
    "    'Attribute8': ['Up', 'Down'],\n",
    "    'Attribute9': ['First', 'Second', 'Third', 'Fourth'],\n",
    "    'Attribute10': ['Dog', 'Cat', 'Bird', 'Fish', 'Rabbit']\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df_skewed = pd.DataFrame()\n",
    "\n",
    "# Generate random data for each attribute\n",
    "for attribute, category_list in categories.items():\n",
    "    if attribute in ['Attribute1', 'Attribute2']:\n",
    "        # Generate uniform distribution\n",
    "        weights = np.ones(len(category_list))\n",
    "        weights = weights / np.sum(weights)\n",
    "        print(attribute, weights)\n",
    "        random_categories = np.random.choice(category_list, size=1000, replace=True, p=weights)\n",
    "    else:\n",
    "        # Generate highly skewed distribution\n",
    "        weights = np.random.rand(len(category_list))\n",
    "        weights = weights / np.sum(weights)   # randomly adjust weights to control skewness\n",
    "        print(attribute, weights)\n",
    "        random_categories = np.random.choice(category_list, size=1000, replace=True, p=weights)\n",
    "    \n",
    "    df_skewed[attribute] = random_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skewed.to_csv('data/df_skewed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniform = pd.DataFrame()\n",
    "\n",
    "categories_diverse = {\n",
    "    'Attribute1': ['Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon', 'Zeta', 'Eta', 'Theta', 'Iota', 'Kappa'],\n",
    "    'Attribute2': ['Red', 'Green', 'Blue', 'Yellow'],\n",
    "    'Attribute3': ['One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine'], # 'Ten', 'Eleven'],\n",
    "    'Attribute4': ['Apple', 'Banana', 'Orange'],\n",
    "    'Attribute5': ['Up', 'Down'],\n",
    "}\n",
    "\n",
    "for attribute, category_list in categories_diverse.items():\n",
    "    weights = np.ones(len(category_list))\n",
    "    weights = weights / np.sum(weights)\n",
    "    print(attribute, weights)\n",
    "    random_categories = np.random.choice(category_list, size=1000, replace=True, p=weights)\n",
    "    df_uniform[attribute] = random_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniform.to_csv('data/df_uniform.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy dataset where every combination of attributes from categories_diverse is covered\n",
    "# Generate all attribute combinations\n",
    "attribute_combinations = list(itertools.product(*categories_diverse.values()))\n",
    "# Shuffle the combinations and add random duplicates\n",
    "random.shuffle(attribute_combinations)\n",
    "attribute_combinations = attribute_combinations + random.choices(attribute_combinations, k=1000)\n",
    "\n",
    "# Create DataFrame\n",
    "df_covered = pd.DataFrame(attribute_combinations, columns=categories_diverse.keys())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covered.to_csv('data/df_covered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 Create toy dataset with synthesized library for scalability tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### large dataframe with 1,500,000 [large] // 150,000 rows [medium] and 13 columns\n",
    "if os.path.isfile('data/adult_synth_medium.csv'):\n",
    "    print(\"File exists\")\n",
    "    df_synth = pd.read_csv('data/adult_synth_large.csv')\n",
    "else:\n",
    "    print(\"File does not exist -> Generate new synthetic data\")\n",
    "    df = df_adult.sample(n=1500, random_state=1)\n",
    "    df_meta = synthesized.MetaExtractor.extract(df)\n",
    "    synthesizer = synthesized.HighDimSynthesizer(df_meta)  \n",
    "    synthesizer.learn(df)\n",
    "    df_synth = synthesizer.synthesize(num_rows=150000)\n",
    "    df_synth.to_csv('data/adult_synth_medium.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synth = df_synth.drop(columns=['education']) # currently to avoid cardinality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random dataframe with 14 columns and 1,000 rows\n",
    "df_synth_short = df_synth.sample(n=1000, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3 Choose one dataset to continue evaluation with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/adult_synth_medium.csv\")\n",
    "df.drop(columns=['native-country'], inplace=True)\n",
    "df = df.iloc[:,:5]\n",
    "df.columns = [s.replace('-', '_') for s in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_skewed.copy()\n",
    "# df = df.drop(columns)\n",
    "# df = df_synth.iloc[:,:5].copy()\n",
    "# df = df_compas.copy()\n",
    "df = df_uniform.copy()\n",
    "df.columns = [s.replace('-', '_') for s in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'?': '--'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>age</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40 to 60</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40 to 60</td>\n",
       "      <td>25 to 45</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40 to 60</td>\n",
       "      <td>25 to 45</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More than 60</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40 to 60</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hours_per_week              age capital_gain capital_loss workclass\n",
       "0       40 to 60     Less than 25           No           No   Private\n",
       "1       40 to 60         25 to 45           No           No   Private\n",
       "2       40 to 60         25 to 45           No           No   Private\n",
       "3   More than 60  Greater than 45           No          Yes   Private\n",
       "4       40 to 60  Greater than 45           No           No        --"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(range(len(df.columns))):\n",
    "    labels, uniques = pd.factorize(df[df.columns[col]])\n",
    "    labels = [str(col) + \":\" + str(l) for l in labels]\n",
    "    df[df.columns[col]] = labels\n",
    "del labels, uniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Add real world examples as reference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Replication of data from ProPublica article (Angwin et al. 2016) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compas_raw = pd.read_csv('data/compas-scores-two-years.csv')\n",
    "df_compas = (df_compas_raw[['age', 'c_charge_degree', 'race', 'age_cat', 'score_text', \n",
    "             'sex', 'priors_count', 'decile_score', 'two_year_recid']]\n",
    "             .loc[(df_compas_raw['days_b_screening_arrest'] <= 30) & (df_compas_raw['days_b_screening_arrest'] >= -30), :]\n",
    "             .loc[df_compas_raw['is_recid'] != -1, :]\n",
    "             .loc[df_compas_raw['c_charge_degree'] != 'O', :]\n",
    "             .loc[df_compas_raw['score_text'] != 'N/A', :]\n",
    "             )\n",
    "print('Number of rows: {}'.format(len(df_compas.index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn compas data into categorical data\n",
    "df_compas['age'] = df_compas['age'].apply(lambda x: 'Less than 25' if x < 25 else '25 to 45' if x < 45 else 'Greater than 45')\n",
    "df_compas['age'] = df_compas['age'].astype('category')\n",
    "\n",
    "df_compas['two_year_recid'] = df_compas['two_year_recid'].replace({0: 'No', 1: 'Yes'})\n",
    "\n",
    "df_compas['decile_score'] = df_compas['decile_score'].apply(lambda x: 'Low' if x <= 4 else 'Medium' if x <= 7 else 'High')\n",
    "\n",
    "df_compas['priors_count'] = df_compas['priors_count'].apply(lambda x: str(x) if x <= 5 else 'More than 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compas.to_csv('data/df_compas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 ACS Income Dataset\n",
    "\n",
    "Use ACSIncome and categorize as closely to Adult Dataset as possible to allow for diversity comparison and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSIncome, adult_filter\n",
    "import folktables\n",
    "\n",
    "ACSIncome_100000 = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    # target_transform=lambda x: x > 100000,\n",
    "    group='RAC1P',\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "ca_data = data_source.get_data(download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_features, ca_labels, _ = ACSIncome_100000.df_to_pandas(ca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_features.join(ca_labels).to_csv('data/df_ACSIncome_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income = ca_features.join(ca_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income = pd.read_csv('data/df_ACSIncome_CA_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4720.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3605.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7330.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2722.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  COW  SCHL  MAR    OCCP  POBP  RELP  WKHP  SEX  RAC1P    PINCP\n",
       "0  18.0  1.0  18.0  5.0  4720.0  13.0  17.0  21.0  2.0    2.0   1600.0\n",
       "1  53.0  5.0  17.0  5.0  3605.0  18.0  16.0  40.0  1.0    1.0  10000.0\n",
       "2  41.0  1.0  16.0  5.0  7330.0   1.0  17.0  40.0  1.0    1.0  24000.0\n",
       "3  18.0  6.0  18.0  5.0  2722.0   1.0  17.0   2.0  2.0    1.0    180.0\n",
       "4  21.0  5.0  19.0  5.0  3870.0  12.0  17.0  50.0  1.0    1.0  29000.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income['age'] = acs_income['AGEP'].apply(lambda x: 'Less than 25' if x < 25 else '25 to 45' if (x >= 25 and x <= 45) else 'Greater than 45')\n",
    "acs_income['age'] = acs_income['age'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult['workclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "COW = {\n",
    "    1: 'Private',\n",
    "    2: 'Private',\n",
    "    3: 'Local-gov',\n",
    "    4: 'State-gov',\n",
    "    5: 'Federal-gov',\n",
    "    6: 'Self-emp-not-inc',\n",
    "    7: 'Self-emp-inc',\n",
    "    8: 'Without-pay',\n",
    "    9: 'Never-worked'\n",
    "}\n",
    "\n",
    "acs_income['workclass'] = acs_income['COW'].replace(COW)\n",
    "acs_income['workclass'] = acs_income['workclass'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4720.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3605.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Federal-gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7330.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>25 to 45</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2722.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Federal-gov</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  COW  SCHL  MAR    OCCP  POBP  RELP  WKHP  SEX  RAC1P    PINCP  \\\n",
       "0  18.0  1.0  18.0  5.0  4720.0  13.0  17.0  21.0  2.0    2.0   1600.0   \n",
       "1  53.0  5.0  17.0  5.0  3605.0  18.0  16.0  40.0  1.0    1.0  10000.0   \n",
       "2  41.0  1.0  16.0  5.0  7330.0   1.0  17.0  40.0  1.0    1.0  24000.0   \n",
       "3  18.0  6.0  18.0  5.0  2722.0   1.0  17.0   2.0  2.0    1.0    180.0   \n",
       "4  21.0  5.0  19.0  5.0  3870.0  12.0  17.0  50.0  1.0    1.0  29000.0   \n",
       "\n",
       "               age         workclass  \n",
       "0     Less than 25           Private  \n",
       "1  Greater than 45       Federal-gov  \n",
       "2         25 to 45           Private  \n",
       "3     Less than 25  Self-emp-not-inc  \n",
       "4     Less than 25       Federal-gov  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHL = {\n",
    "    1: '?',\n",
    "    2: 'Preschool',\n",
    "    3: 'Preschool',\n",
    "    4: '1st-4th',\n",
    "    5: '1st-4th',\n",
    "    6: '1st-4th',\n",
    "    7: '1st-4th',\n",
    "    8: '5th-6th',\n",
    "    9: '5th-6th',\n",
    "    10: '7th-8th',\n",
    "    11: '7th-8th',\n",
    "    12: '9th',\n",
    "    13: '10th',\n",
    "    14: '11th',\n",
    "    15: '12th',\n",
    "    16: 'HS-grad',\n",
    "    17: 'HS-grad',\n",
    "    18: 'Some-college',\n",
    "    19: 'Some-college',\n",
    "    20: 'Assoc-voc',\n",
    "    21: 'Bachelors',\n",
    "    22: 'Masters',\n",
    "    23: 'Prof-school',\n",
    "    24: 'Doctorate',\n",
    "}\n",
    "\n",
    "acs_income['education'] = acs_income['SCHL'].replace(SCHL)\n",
    "acs_income['education'] = acs_income['education'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated',\n",
       "       'Widowed', 'Married-spouse-absent', 'Married-AF-spouse'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult['marital-status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAR = {\n",
    "    1: 'Married-civ-spouse',\n",
    "    2: 'Widowed',\n",
    "    3: 'Divorced',\n",
    "    4: 'Separated',\n",
    "    5: 'Never-married'\n",
    "}\n",
    "\n",
    "acs_income['marital-status'] = acs_income['MAR'].replace(MAR)\n",
    "acs_income['marital-status'] = acs_income['marital-status'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEX = {\n",
    "    1: \"Male\",\n",
    "    2: \"Female\"\n",
    "}\n",
    "\n",
    "acs_income['gender'] = acs_income['SEX'].replace(SEX)\n",
    "acs_income['gender'] = acs_income['gender'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United-States', 'Cambodia', '?', 'England', 'Puerto-Rico',\n",
       "       'Canada', 'Germany', 'Outlying-US(Guam-USVI-etc)', 'India',\n",
       "       'Japan', 'Greece', 'South', 'China', 'Cuba', 'Iran', 'Honduras',\n",
       "       'Philippines', 'Italy', 'Poland', 'Jamaica', 'Vietnam', 'Mexico',\n",
       "       'Portugal', 'Ireland', 'France', 'Dominican-Republic', 'Laos',\n",
       "       'Ecuador', 'Taiwan', 'Haiti', 'Columbia', 'Hungary', 'Guatemala',\n",
       "       'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador',\n",
       "       'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult['native-country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "POBP = {\n",
    "100: \"Albania\",\n",
    "102: \"Austria\",\n",
    "103: \"Belgium\",\n",
    "104: \"Bulgaria\",\n",
    "105: \"Czechoslovakia\",\n",
    "106: \"Denmark\",\n",
    "108: \"Finland\",\n",
    "109: \"France\",\n",
    "110: \"Germany\",\n",
    "116: \"Greece\",\n",
    "117: \"Hungary\",\n",
    "118: \"Iceland\",\n",
    "119: \"Ireland\",\n",
    "120: \"Italy\",\n",
    "126: \"Netherlands\",\n",
    "127: \"Norway\",\n",
    "128: \"Poland\",\n",
    "129: \"Portugal\",\n",
    "130: \"Azores Islands\",\n",
    "132: \"Romania\",\n",
    "134: \"Spain\",\n",
    "136: \"Sweden\",\n",
    "137: \"Switzerland\",\n",
    "138: \"United Kingdom, Not Specified\",\n",
    "139: \"England\",\n",
    "140: \"Scotland\",\n",
    "142: \"Northern Ireland (2017 or later)\",\n",
    "147: \"Yugoslavia\",\n",
    "148: \"Czech Republic\",\n",
    "149: \"Slovakia\",\n",
    "150: \"Bosnia and Herzegovina\",\n",
    "151: \"Croatia\",\n",
    "152: \"Macedonia\",\n",
    "154: \"Serbia\",\n",
    "156: \"Latvia\",\n",
    "157: \"Lithuania\",\n",
    "158: \"Armenia\",\n",
    "159: \"Azerbaijan\",\n",
    "160: \"Belarus\",\n",
    "161: \"Georgia\",\n",
    "162: \"Moldova\",\n",
    "163: \"Russia\",\n",
    "164: \"Ukraine\",\n",
    "165: \"USSR\",\n",
    "166: \"Europe (2017 or later)\",\n",
    "167: \"Kosovo (2017 or later)\",\n",
    "168: \"Montenegro\",\n",
    "169: \"Other Europe, Not Specified\",\n",
    "200: \"Afghanistan\",\n",
    "202: \"Bangladesh\",\n",
    "203: \"Bhutan\",\n",
    "205: \"Myanmar\",\n",
    "206: \"Cambodia\",\n",
    "207: \"China\",\n",
    "208: \"Cyprus (2016 or earlier)\",\n",
    "209: \"Hong Kong\",\n",
    "210: \"India\",\n",
    "211: \"Indonesia\",\n",
    "212: \"Iran\",\n",
    "213: \"Iraq\",\n",
    "214: \"Israel\",\n",
    "215: \"Japan\",\n",
    "216: \"Jordan\",\n",
    "217: \"Korea\",\n",
    "218: \"Kazakhstan\",\n",
    "219: \"Kyrgyzstan (2017 or later)\",\n",
    "222: \"Kuwait\",\n",
    "223: \"Laos\",\n",
    "224: \"Lebanon\",\n",
    "226: \"Malaysia\",\n",
    "228: \"Mongolia (2017 or later)\",\n",
    "229: \"Nepal\",\n",
    "231: \"Pakistan\",\n",
    "233: \"Philippines\",\n",
    "235: \"Saudi Arabia\",\n",
    "236: \"Singapore\",\n",
    "238: \"Sri Lanka\",\n",
    "239: \"Syria\",\n",
    "240: \"Taiwan\",\n",
    "242: \"Thailand\",\n",
    "243: \"Turkey\",\n",
    "245: \"United Arab Emirates\",\n",
    "246: \"Uzbekistan\",\n",
    "247: \"Vietnam\",\n",
    "248: \"Yemen\",\n",
    "249: \"Asia\",\n",
    "253: \"South Central Asia, Not Specified\",\n",
    "254: \"Other Asia, Not Specified\",\n",
    "300: \"Bermuda\",\n",
    "301: \"Canada\",\n",
    "303: \"Mexico\",\n",
    "310: \"Belize\",\n",
    "311: \"Costa Rica\",\n",
    "312: \"El Salvador\",\n",
    "313: \"Guatemala\",\n",
    "314: \"Honduras\",\n",
    "315: \"Nicaragua\",\n",
    "316: \"Panama\",\n",
    "321: \"Antigua and Barbuda\",\n",
    "323: \"Bahamas\",\n",
    "324: \"Barbados\",\n",
    "327: \"Cuba\",\n",
    "328: \"Dominica\",\n",
    "329: \"Dominican Republic\",\n",
    "330: \"Grenada\",\n",
    "332: \"Haiti\",\n",
    "333: \"Jamaica\",\n",
    "338: \"St. Kitts-Nevis (2017 or later)\",\n",
    "339: \"St. Lucia\",\n",
    "340: \"St. Vincent and the Grenadines\",\n",
    "341: \"Trinidad and Tobago\",\n",
    "343: \"West Indies\",\n",
    "344: \"Caribbean, Not Specified\",\n",
    "360: \"Argentina\",\n",
    "361: \"Bolivia\",\n",
    "362: \"Brazil\",\n",
    "363: \"Chile\",\n",
    "364: \"Colombia\",\n",
    "365: \"Ecuador\",\n",
    "368: \"Guyana\",\n",
    "369: \"Paraguay\",\n",
    "370: \"Peru\",\n",
    "372: \"Uruguay\",\n",
    "373: \"Venezuela\",\n",
    "374: \"South America\",\n",
    "399: \"Americas, Not Specified\",\n",
    "400: \"Algeria\",\n",
    "407: \"Cameroon\",\n",
    "408: \"Cabo Verde\",\n",
    "412: \"Congo\",\n",
    "414: \"Egypt\",\n",
    "416: \"Ethiopia\",\n",
    "417: \"Eritrea\",\n",
    "420: \"Gambia\",\n",
    "421: \"Ghana\",\n",
    "423: \"Guinea\",\n",
    "425: \"Ivory Coast (2017 or later)\",\n",
    "427: \"Kenya\",\n",
    "429: \"Liberia\",\n",
    "430: \"Libya\",\n",
    "436: \"Morocco\",\n",
    "440: \"Nigeria\",\n",
    "442: \"Rwanda (2017 or later)\",\n",
    "444: \"Senegal\",\n",
    "447: \"Sierra Leone\",\n",
    "448: \"Somalia\",\n",
    "449: \"South Africa\",\n",
    "451: \"Sudan\",\n",
    "453: \"Tanzania\",\n",
    "454: \"Togo\",\n",
    "456: \"Tunisia (2017 or later)\",\n",
    "457: \"Uganda\",\n",
    "459: \"Democratic Republic of Congo (Zaire)\",\n",
    "460: \"Zambia\",\n",
    "461: \"Zimbabwe\",\n",
    "462: \"Africa\",\n",
    "463: \"South Sudan (2017 or later)\",\n",
    "464: \"Northern Africa, Not Specified\",\n",
    "467: \"Western Africa, Not Specified\",\n",
    "468: \"Other Africa, Not Specified\",\n",
    "469: \"Eastern Africa, Not Specified\",\n",
    "501: \"Australia\",\n",
    "508: \"Fiji\",\n",
    "511: \"Marshall Islands\",\n",
    "512: \"Micronesia\",\n",
    "515: \"New Zealand\",\n",
    "523: \"Tonga\",\n",
    "527: \"Samoa\",\n",
    "554: \"Other US Island Areas, Oceania, Not Specified, or at Sea\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income['native-country'] = acs_income['POBP'].apply(lambda x: 'United-States' if x < 100 else x)\n",
    "acs_income['native-country'] = acs_income['native-country'].replace(POBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all except the 49 highest frequency countries with 'Other'\n",
    "for country in acs_income['native-country'].value_counts().index[49:]:\n",
    "    acs_income['native-country'] = acs_income['native-country'].replace(country, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other',\n",
       "       'Black'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "RACE = {\n",
    "    1: 'White',\n",
    "    2: 'Black',\n",
    "    3: 'American Indian',\n",
    "    4: 'Alaska Native',\n",
    "    5: 'Amer-Indian-Native-Specified',\n",
    "    6: 'Asian',\n",
    "    7: 'Asian-Pac-Islander',\n",
    "    8: 'Other',\n",
    "    9: 'Two or more races',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income['race'] = acs_income['RAC1P'].replace(RACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income['race'] = acs_income['race'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGEP', 'COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'RELP', 'WKHP', 'SEX',\n",
       "       'RAC1P', 'PINCP', 'age', 'workclass', 'education', 'marital-status',\n",
       "       'gender', 'native-country', 'race'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_income.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bucketize PINCP in 10,000 dollar increments and convert to category (e.g. \"0-10,000\", \"10,000-20,000\", etc.)\n",
    "acs_income[\"income\"] = pd.cut(acs_income[\"PINCP\"], bins=np.arange(0, 500000, 10000), labels=[f\"${i}-{i+10}k\" for i in range(0, 490, 10)])\n",
    "#fill in missing values with above 500k category\n",
    "acs_income[\"income\"] = acs_income[\"income\"].cat.add_categories(f\"$490k+\")\n",
    "acs_income[\"income\"] = acs_income[\"income\"].fillna(\"$490k+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income['income'] = acs_income['income'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGEP                 80\n",
       "COW                   8\n",
       "SCHL                 24\n",
       "MAR                   5\n",
       "OCCP                529\n",
       "POBP                224\n",
       "RELP                 18\n",
       "WKHP                 99\n",
       "SEX                   2\n",
       "RAC1P                 9\n",
       "PINCP             18107\n",
       "age                   3\n",
       "workclass             7\n",
       "education            16\n",
       "marital-status        5\n",
       "gender                2\n",
       "native-country       50\n",
       "race                  9\n",
       "income               50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_income.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acs_income['income'] = acs_income['PINCP'].apply(lambda x: '<=50K' if x == False else '>50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Less than 40', '40 to 60', 'More than 60']\n",
       "Categories (3, object): ['40 to 60', 'Less than 40', 'More than 60']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult['hours-per-week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income['hours-per-week'] = acs_income['WKHP'].apply(lambda x: 'Less than 40' if x < 40 else '40 to 60' if (x >= 40 and x<= 60) else 'More than 60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_adult.columns)-set(acs_income.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195665"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acs_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income[['age', 'workclass', 'education', 'marital-status',\n",
    "       'gender', 'native-country', 'race', 'income', 'hours-per-week']].to_csv('data/df_ACSIncome.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income_mexico = acs_income.loc[acs_income['native-country'] == 'Mexico', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income_mexico.to_csv('data/df_ACSIncome_Mexico.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57275"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acs_income_mexico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Add Reference Dataset for Adult Dataset (UCI Adult dataset)\n",
    "Folktables Adult Dataset should be an updated version of UCI Adult dataset.\n",
    "\n",
    "Therefore uci_adult can be reference for ACSIncome (and have similar diversity profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_adult_reference_link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "        \"occupation\", \"relationship\", \"race\", \"gender\", \"capital-gain\", \"capital-loss\",\n",
    "        \"hours-per-week\", \"native-country\", \"income\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_adult = pd.read_csv(uci_adult_reference_link, names=features, sep=r'\\s*,\\s*', \n",
    "                             engine='python', na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_adult = uci_adult.drop(['fnlwgt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_adult.fillna(\"?\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(uci_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25 to 45</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>More than 12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>40 to 60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>More than 12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Less than 40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25 to 45</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>8 to 12</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>40 to 60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Less than 8</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>40 to 60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25 to 45</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>More than 12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>40 to 60</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age         workclass  education education-num  \\\n",
       "0         25 to 45         State-gov  Bachelors  More than 12   \n",
       "1  Greater than 45  Self-emp-not-inc  Bachelors  More than 12   \n",
       "2         25 to 45           Private    HS-grad       8 to 12   \n",
       "3  Greater than 45           Private       11th   Less than 8   \n",
       "4         25 to 45           Private  Bachelors  More than 12   \n",
       "\n",
       "       marital-status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "  capital-gain capital-loss hours-per-week native-country income  \n",
       "0          Yes           No       40 to 60  United-States  <=50K  \n",
       "1           No           No   Less than 40  United-States  <=50K  \n",
       "2           No           No       40 to 60  United-States  <=50K  \n",
       "3           No           No       40 to 60  United-States  <=50K  \n",
       "4           No           No       40 to 60           Cuba  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uci_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_adult['hours-per-week'] = uci_adult['hours-per-week'].astype('int')\n",
    "uci_adult['age'] = uci_adult['age'].astype('int')\n",
    "uci_adult['education-num'] = uci_adult['education-num'].astype('int')\n",
    "uci_adult['capital-gain'] = uci_adult['capital-gain'].astype('int')\n",
    "uci_adult['capital-loss'] = uci_adult['capital-loss'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_adult['age'] = uci_adult['age'].apply(lambda x: 'Less than 25' if x < 25 else '25 to 45' if x < 45 else 'Greater than 45')\n",
    "uci_adult['age'] = uci_adult['age'].astype('category')\n",
    "\n",
    "uci_adult['hours-per-week'] = uci_adult['hours-per-week'].apply(lambda x: 'Less than 40' if x < 40 else '40 to 60' if x < 60 else 'More than 60')\n",
    "uci_adult['hours-per-week'] = uci_adult['hours-per-week'].astype('category')\n",
    "\n",
    "uci_adult['education-num'] = uci_adult['education-num'].apply(lambda x: 'Less than 8' if x < 8 else '8 to 12' if x < 12 else 'More than 12')\n",
    "uci_adult['education-num'] = uci_adult['education-num'].astype('category')\n",
    "\n",
    "uci_adult['capital-gain'] = uci_adult['capital-gain'].apply(lambda x: 'No' if x == 0 else 'Yes')\n",
    "uci_adult['capital-gain'] = uci_adult['capital-gain'].astype('category')\n",
    "\n",
    "uci_adult['capital-loss'] = uci_adult['capital-loss'].apply(lambda x: 'No' if x == 0 else 'Yes')\n",
    "uci_adult['capital-loss'] = uci_adult['capital-loss'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: set()\n",
      "workclass: set()\n",
      "education: set()\n",
      "education-num: set()\n",
      "marital-status: set()\n",
      "occupation: set()\n",
      "relationship: set()\n",
      "race: set()\n",
      "gender: set()\n",
      "capital-gain: set()\n",
      "capital-loss: set()\n",
      "hours-per-week: set()\n",
      "native-country: set()\n",
      "income: set()\n"
     ]
    }
   ],
   "source": [
    "for col in uci_adult.columns:\n",
    "    print(f\"{col}: {set(uci_adult[col].unique())-set(df_adult[col].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_adult.to_csv(\"data/df_uci_adult.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reference Projection for Adult Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_adult with only gender=male and race=white\n",
    "df_adult = pd.read_csv(\"data/df_uci_adult.csv\")\n",
    "df_adult_mw = df_adult[(df_adult['gender']=='Male') & (df_adult['race']=='White')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult_mw.to_csv('data/df_uci_adult_mw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using row-based traversal\n",
      "using row-based traversal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7700/7700 [00:36<00:00, 208.16it/s]\n"
     ]
    }
   ],
   "source": [
    "all_occurences, keys = occ.get_occurence_count(df_adult_mw, max_level=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_occurences[\"('age:Less than 25',)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('age:Less than 25',): 0, ('education:Doctorate',): 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov.get_occurences_of_parent_patterns(('age:Less than 25', 'education:Doctorate'), all_occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Add UK Road Safety Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download UKRoadSafety data from https://www.kaggle.com/datasets/tsiaras/uk-road-safety-accidents-and-vehicles/data. We use the Accident Information data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accident_info = pd.read_csv(\"data/UK_RoadSafety_Accident_Information.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accident_Index                2047256\n",
       "1st_Road_Class                      6\n",
       "2nd_Road_Class                      6\n",
       "Accident_Severity                   3\n",
       "Carriageway_Hazards                 7\n",
       "Date                             4748\n",
       "Day_of_Week                         7\n",
       "Junction_Control                    6\n",
       "Junction_Detail                    10\n",
       "Light_Conditions                    6\n",
       "Local_Authority_(District)        416\n",
       "Local_Authority_(Highway)         207\n",
       "LSOA_of_Accident_Location       35564\n",
       "Police_Force                       51\n",
       "Road_Surface_Conditions             6\n",
       "Road_Type                           7\n",
       "Special_Conditions_at_Site          9\n",
       "Time                             1439\n",
       "Urban_or_Rural_Area                 3\n",
       "Weather_Conditions                 10\n",
       "InScotland                          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all object columns\n",
    "df_accident_info_col = df_accident_info.select_dtypes(include=['object'])\n",
    "df_accident_info_col.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accident_info = df_accident_info[[\"Light_Conditions\", \"Weather_Conditions\", \"Road_Type\", \"Day_of_Week\", \"Speed_limit\", \"Urban_or_Rural_Area\", \"Accident_Severity\", \"Road_Surface_Conditions\", \"Year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Light_Conditions            object\n",
       "Weather_Conditions          object\n",
       "Road_Type                   object\n",
       "Day_of_Week                 object\n",
       "Speed_limit                float64\n",
       "Urban_or_Rural_Area         object\n",
       "Accident_Severity           object\n",
       "Road_Surface_Conditions     object\n",
       "Year                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dtype of all columns\n",
    "df_accident_info.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Light_Conditions            6\n",
       "Weather_Conditions         10\n",
       "Road_Type                   7\n",
       "Day_of_Week                 7\n",
       "Speed_limit                 9\n",
       "Urban_or_Rural_Area         3\n",
       "Accident_Severity           3\n",
       "Road_Surface_Conditions     6\n",
       "Year                       13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get cardinality of every column\n",
    "df_accident_info.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119991"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_accident_info.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Light_Conditions', 'Weather_Conditions', 'Road_Type', 'Day_of_Week',\n",
       "       'Speed_limit', 'Urban_or_Rural_Area', 'Accident_Severity',\n",
       "       'Road_Surface_Conditions', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accident_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accident_info.to_csv(\"data/df_uk_road_accident.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "df_accident_info_enc = occ.encode_data_pure(df_accident_info)\n",
    "df_accident_info_enc.to_csv(\"data/df_uk_road_accident_enc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Add BlueNile dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the BlueNile dataset from the CoverageJava repo of the baseline DeepDiver algorithm: https://github.com/UIC-InDeXLab/MithraLabel/tree/master/CoverageJava/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_raw = pd.read_csv(\"CoverageJava/data/BN-2-21-2018-n116300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Carat', 'Clarity', 'Color', 'Cut', 'Depth', 'Fluorescence', 'ID',\n",
       "       'LengthWidthRatio', 'Polish', 'Price', 'Shape', 'Symmetry', 'Table',\n",
       "       'Carat_norm', 'Clarity_norm', 'Color_norm', 'Cut_norm', 'Depth_norm',\n",
       "       'LengthWidthRatio_norm', 'Price_inv_norm', 'Table_norm', 'Rand#'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = bn_raw[[\"Shape\", \"Color\", \"Cut\", \"Clarity\", \"Polish\", \"Symmetry\", \"Fluorescence\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.to_csv(\"data/df_diamonds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dataset from CoverageJava paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_raw_num = pd.read_csv(\"data/bluenile_raw.csv\")\n",
    "bn_num = bn_raw_num[bn_raw_num.columns[1:]]\n",
    "bn_num.columns = [\"Shape\", \"Color\", \"Cut\", \"Clarity\", \"Polish\", \"Symmetry\", \"Fluorescence\"]\n",
    "bn_num.to_csv(\"data/df_num_diamonds_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import src.occurence_estimation as occ\n",
    "bn_num_cat, mapping = occ.factorize_data(bn_num)\n",
    "bn_num_cat.to_csv(\"data/df_num_diamonds_enc_num.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Add IMDb dataset\n",
    "\n",
    "source: https://developer.imdb.com/non-commercial-datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7m/gfw5j53x1hx29cv80bbnf50m0000gp/T/ipykernel_98882/2560924856.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  imdb_table=pd.read_table(\"data/imdb_basics_data.tsv\", index_col=\"tconst\", na_values=\"\\\\N\")\n"
     ]
    }
   ],
   "source": [
    "# reading given tsv file\n",
    "imdb_table=pd.read_table(\"data/imdb_basics_data.tsv\", index_col=\"tconst\", na_values=\"\\\\N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_table = imdb_table[[\"titleType\", \"isAdult\", \"startYear\", \"runtimeMinutes\", \"genres\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "titleType         10\n",
       "isAdult            2\n",
       "startYear         18\n",
       "runtimeMinutes     7\n",
       "genres            28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_table.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out rows with unaligned data\n",
    "imdb_table = imdb_table[imdb_table.isAdult < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucketize startYear in 10 year buckets (e.g. 1990-1999)\n",
    "imdb_table[\"startYear\"] = imdb_table[\"startYear\"].apply(lambda x: str(x)[:3] + \"0s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(imdb_table[\"runtimeMinutes\"].value_counts()).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize runtimeMinutes into 30 min buckets\n",
    "imdb_table[\"runtimeMinutes\"] = imdb_table[\"runtimeMinutes\"].astype(float).apply(lambda x: x if pd.isna(x) else \"<30min\" if x < 30 else \"30-60min\" if x < 60 else \"60-90min\" if x < 90 else \"90-120min\" if x < 120 else \">120min\" if x < 180 else \">180min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN values in runtimeMinutes with \"unknown\"\n",
    "imdb_table[\"runtimeMinutes\"] = imdb_table[\"runtimeMinutes\"].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all rows where genres is not string\n",
    "imdb_table = imdb_table[imdb_table.genres.apply(lambda x: isinstance(x, str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce number of genres by only using first genre\n",
    "imdb_table[\"genres\"] = imdb_table[\"genres\"].apply(lambda x: x.split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop index column\n",
    "imdb_table = imdb_table.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_table.to_csv(\"data/imdb_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 add IMDb Top 7000 dataset\n",
    "\n",
    "source: https://www.kaggle.com/datasets/mazenramadan/imdb-most-popular-films-and-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_top = pd.read_csv(\"data/imdb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name           4820\n",
       "Date             11\n",
       "Rate             10\n",
       "Votes          4802\n",
       "Genre            23\n",
       "Duration          7\n",
       "Type              2\n",
       "Certificate      23\n",
       "Episodes        284\n",
       "Nudity            5\n",
       "Violence          5\n",
       "Profanity         5\n",
       "Alcohol           5\n",
       "Frightening       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_top.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce number of genres by only using first genre\n",
    "imdb_top[\"Genre\"] = imdb_top[\"Genre\"].apply(lambda x: x.split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize Rate to buckets of 0-10 in steps of 1 as \"0-1\" etc.\n",
    "imdb_top[\"Rate\"] = imdb_top[\"Rate\"].apply(lambda x: str(int(float(x))) + \"-\" + str(int(float(x))+1) if x != \"No Rate\" else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce duration to buckets of 30 min\n",
    "imdb_top[\"Duration\"] = imdb_top[\"Duration\"].apply(lambda x: x if x==\"None\" else \"<30min\" if float(x) < 30 else \"30-60min\" if float(x) < 60 else \"60-90min\" if float(x) < 90 else \"90-120min\" if float(x) < 120 else \">120min\" if float(x) < 180 else \">180min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce number of years to buckets of 10 years\n",
    "imdb_top[\"Date\"] = imdb_top[\"Date\"].apply(lambda x: str(x)[:3] + \"0s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_top.to_csv(\"data/imdb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 add Covertype Dataset\n",
    "\n",
    "Test with ecology dataset. Source is https://networkrepository.com/covtype.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "covertype = pd.read_csv(\"data/covtype.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40', 'Cover_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covertype.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn binary columns Soil_Type1 to Soil_Type40 into one categorical column \"Soil Type\" with values 1-40\n",
    "covertype[\"SoilType\"] = pd.Series(covertype[covertype.columns[14:54]].idxmax(axis=1)).apply(lambda x: int(x.split(\"e\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn binary columns Wilderness_Area1 to Wilderness_Area4 into one categorical column \"Wilderness Area\" with values 1-4\n",
    "covertype[\"WildernessArea\"] = pd.Series(covertype[covertype.columns[10:14]].idxmax(axis=1)).apply(lambda x: int(x.split(\"a\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Soil_Type1 to Soil_Type40 and Wilderness_Area1 to Wilderness_Area4\n",
    "covertype = covertype.drop(columns=covertype.columns[10:54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bucketize Elevation into 500m buckets (e.g. 2000-2500)\n",
    "covertype[\"Elevation\"] = covertype[\"Elevation\"].apply(lambda x: str(int(x/500)*500) + \"-\" + str(int(x/500)*500+500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000-3500    284467\n",
       "2500-3000    252947\n",
       "2000-2500     39800\n",
       "3500-4000      2540\n",
       "1500-2000      1258\n",
       "Name: Elevation, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covertype.Elevation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "covertype.to_csv(\"data/covertype.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Save all selected Datasets in encoded versions\n",
    "- ACSIncome\n",
    "- ACSIncome, filtered for CA\n",
    "- UKRoadSafety\n",
    "- BlueNile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income_ca = pd.read_csv('data/df_ACSIncome_CA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income_ca_enc = occ.encode_data_pure(acs_income_ca)\n",
    "acs_income_ca_enc.to_csv('data/df_ACSIncome_CA_enc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income = pd.read_csv('data/df_ACSIncome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:08<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "acs_income_enc = occ.encode_data_pure(acs_income)\n",
    "acs_income_enc.to_csv('data/df_ACSIncome_enc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_roadsafety = pd.read_csv('data/df_uk_road_accident.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:08<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "uk_roadsafety_enc = occ.encode_data_pure(uk_roadsafety)\n",
    "uk_roadsafety_enc.to_csv('data/df_uk_road_accident_enc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_income_ca_enc_select = acs_income_ca_enc[[\"education\", \"gender\", \"income\", \"race\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using row-based traversal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2736 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2736/2736 [00:00<00:00, 9860.28it/s]\n"
     ]
    }
   ],
   "source": [
    "freq_count, keys = occ.calc_occurences_countmin_rowbased_traversal(acs_income_ca_enc_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 90.11it/s]\n"
     ]
    }
   ],
   "source": [
    "frequencies_general = occ.get_general_occurences(list(acs_income_ca_enc_select.columns), keys, freq_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
